{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SkimLit: Skimming Literature with NLP\n",
    "\n",
    "This notebook uses natural language processing techniques to analyze and classify sentences from scientific abstracts. The goal is to automate the extraction of important information from scientific papers, which is crucial for researchers and professionals who need to quickly review and understand the literature.\n",
    "\n",
    "## Required Datasets\n",
    "\n",
    "**PubMed 20k RCT Dataset**:\n",
    "\n",
    "This notebook utilizes text files from the `PubMed_20k_RCT_numbers_replaced_with_at_sign` folder, which should be downloaded and stored in a `data` directory accessible by the notebook.\n",
    "\n",
    "### How to Download Dataset\n",
    "\n",
    "To access and set up the datasets, please follow these steps:\n",
    "\n",
    "1. Create a `data` folder in your project directory if it doesn't already exist.\n",
    "2. Download the text files from the following Kaggle dataset link:\n",
    "   - [PubMed 20k RCT Dataset](https://www.kaggle.com/datasets/matthewjansen/pubmed-200k-rtc?select=PubMed_200k_RCT_numbers_replaced_with_at_sign) (ensure you comply with the dataset's usage rules).\n",
    "3. Place the downloaded text files into the `data` folder. This step ensures that all data files are ready to be accessed by the notebook.\n",
    "\n",
    "## Contents of the Notebook\n",
    "\n",
    "- **Introduction**: Overview of the project's aim and importance.\n",
    "- **Basic Exploratory Data Analysis**: Initial analysis of the data to understand the distribution and nature of the dataset.\n",
    "- **Text Normalization**: Processing steps to clean and normalize the text data.\n",
    "- **Model Building**: Implementation of various models to classify sentences in scientific abstracts.\n",
    "- **Model Evaluation**: Evaluation of the models' performance using appropriate metrics.\n",
    "\n",
    " ## Install Required Packages\n",
    "\n",
    "- To enhance the functionality of the CoreAI environment, you may need to install some libraries not pre-installed but required for this notebook. Follow these steps to install the necessary libraries from the `requirements.txt` file:\n",
    "\n",
    " ### Create and Activate the Virtual Environment:\n",
    "   \n",
    "   Open your terminal or command prompt within the jupyter notebook. `File -> New -> Terminal`\n",
    "   \n",
    "   Navigate to the project directory where you want to set up the environment.\n",
    "   \n",
    "   Execute the following commands in a `bash` to create and activate the virtual environment:\n",
    "   \n",
    "   ```\n",
    "   python3 -m venv --system-site-packages myvenv\n",
    "   source myvenv/bin/activate\n",
    "   pip3 install ipykernel\n",
    "   python -m ipykernel install --user --name=myvenv --display-name=\"Python (myvenv)\"\n",
    "   ```\n",
    "\n",
    "### Important Note\n",
    "\n",
    "It is crucial to load the new \"myvenv\" kernel for the notebook to work correctly. If the new \"myvenv\" kernel is not loaded, the required libraries and environment settings will not be applied, and the notebook will not function as expected.\n",
    "\n",
    " ### Install Required Libraries\n",
    "   \n",
    "   Before running the following command in jupyter notebook, make sure you are in the directory where the Jupyter Notebook and virtual environment is located. This ensures the ./ path is always current. You can use the cd command to change to your project directory and pwd to verify your current directory.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_4uoLDr-2b1"
   },
   "outputs": [],
   "source": [
    "# Confirm that tf_keras matches the TF version (to avoid an unnecessary upgrade)\n",
    "!. ./myvenv/bin/activate; pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_hub as tfhub\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "from helper_functions import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.pipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3NFeEsXDmk9G"
   },
   "outputs": [],
   "source": [
    "LOGS_DIR = 'logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "adhR6TajIoMu"
   },
   "outputs": [],
   "source": [
    "data_dir_path = './data/'\n",
    "train_dir_path = data_dir_path + 'train.txt'\n",
    "test_dir_path = data_dir_path + 'test.txt'\n",
    "validation_dir_path = data_dir_path + 'dev.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mk29v3QVJ-yS",
    "outputId": "2684638c-0d2e-4a61-d133-fd0738f1df55"
   },
   "outputs": [],
   "source": [
    "filenames = [data_dir_path + filename for filename in os.listdir(data_dir_path)]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "73RVapwTKEmJ"
   },
   "outputs": [],
   "source": [
    "def read_doc(filename):\n",
    "  \"\"\"\n",
    "  Reads filename (txt) and returns the lines of text as a list\n",
    "\n",
    "  Args:\n",
    "\n",
    "    filename: A string containing the target filepath\n",
    "\n",
    "  Returns:\n",
    "\n",
    "    A list of strings with one string per line from the target filename\n",
    "  \"\"\"\n",
    "  with open(filename, 'r') as f:\n",
    "    return f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0EDwtq6PMaPA",
    "outputId": "9b901f87-80a7-4dc6-933b-eaf3a8117ac0"
   },
   "outputs": [],
   "source": [
    "train_lines = read_doc(train_dir_path)\n",
    "train_lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDdHf6HGMxsF"
   },
   "outputs": [],
   "source": [
    "def preprocess_doc(filename):\n",
    "  \"\"\"\n",
    "  Returns a list of dictionaries for each line relating to one abstract, doing the same for all abstracts\n",
    "\n",
    "  Args:\n",
    "\n",
    "    filename: A string which is the path of the doc\n",
    "\n",
    "  Returns:\n",
    "\n",
    "    A list of dictionaries with preprocesse data from the doc\n",
    "  \"\"\"\n",
    "  input_lines = read_doc(filename)\n",
    "  abstract_lines = ''\n",
    "  abstract_samples = []\n",
    "\n",
    "  for line in input_lines:\n",
    "    if line.startswith('###'):\n",
    "      abstract_id = line\n",
    "      abstract_lines = ''\n",
    "    elif line.isspace():\n",
    "      abstract_line_split = abstract_lines.splitlines()\n",
    "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
    "        line_data = {}\n",
    "        label_text_split = abstract_line.split('\\t')\n",
    "        line_data['line_number'] = abstract_line_number\n",
    "        line_data['label'] = label_text_split[0]\n",
    "        line_data['text'] = label_text_split[1].lower()\n",
    "        line_data['total_lines'] = len(abstract_line_split) - 1\n",
    "        abstract_samples.append(line_data)\n",
    "    else:\n",
    "      abstract_lines += line\n",
    "\n",
    "  return abstract_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ynQ9SgqFE8j",
    "outputId": "573b21fc-cda6-492a-e9dd-070c208b1a70"
   },
   "outputs": [],
   "source": [
    "train_samples = preprocess_doc(train_dir_path)\n",
    "validation_samples = preprocess_doc(validation_dir_path)\n",
    "test_samples = preprocess_doc(test_dir_path)\n",
    "len(train_samples), len(validation_samples), len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yRUDDDxJFqxU",
    "outputId": "19f47f9a-ace1-47e0-daa4-72536579d878"
   },
   "outputs": [],
   "source": [
    "train_samples[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "haV4DyN_GMR2"
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_samples)\n",
    "validation_df = pd.DataFrame(validation_samples)\n",
    "test_df = pd.DataFrame(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "KFxoQdyeGyQ8",
    "outputId": "456d868f-6ac9-4f38-8d24-39d0ec756426"
   },
   "outputs": [],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fTfFgygkG52z",
    "outputId": "b1a9ecaa-45f5-4fa0-8c82-fe3d8e1df77c"
   },
   "outputs": [],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "3-zb9u7fHsyK",
    "outputId": "ed1be524-9564-497e-f740-c06aa27d2b79"
   },
   "outputs": [],
   "source": [
    "train_df['total_lines'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iVxmAP9tHyqc"
   },
   "outputs": [],
   "source": [
    "train_sentences = train_df['text'].to_list()\n",
    "validation_sentences = validation_df['text'].to_list()\n",
    "test_sentences = test_df['text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i7X_wekEIWVv",
    "outputId": "a17692e5-12d2-4bcf-9559-d9f50752b5a3"
   },
   "outputs": [],
   "source": [
    "train_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDaHoX45IX_p"
   },
   "outputs": [],
   "source": [
    "one_hot_encoder = OneHotEncoder(sparse_output = False)\n",
    "train_labels_one_hot_encoded = one_hot_encoder.fit_transform(train_df['label'].to_numpy().reshape(-1,1))\n",
    "validation_labels_one_hot_encoded = one_hot_encoder.transform(validation_df['label'].to_numpy().reshape(-1,1))\n",
    "test_labels_one_hot_encoded = one_hot_encoder.transform(test_df['label'].to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qc2P17xK0Dy"
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "train_labels_label_encoded = label_encoder.fit_transform(train_df['label'].to_numpy())\n",
    "validation_labels_label_encoded = label_encoder.transform(validation_df['label'].to_numpy())\n",
    "test_labels_label_encoded = label_encoder.transform(test_df['label'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D2m1LmTlLYvI",
    "outputId": "9a7ba800-e744-4369-c324-2d28f5a3f8f3"
   },
   "outputs": [],
   "source": [
    "total_classes = len(label_encoder.classes_)\n",
    "class_names = label_encoder.classes_\n",
    "total_classes, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "KmOlA6SrLu26",
    "outputId": "743bbcc5-a30d-4c62-966e-7056870f6708"
   },
   "outputs": [],
   "source": [
    "baseline_model = Pipeline([\n",
    "    ('tf-idf', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "baseline_model.fit(X = train_sentences,\n",
    "                   y = train_labels_label_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ak2g6DXaNPBT",
    "outputId": "89588924-7b13-4bec-e0a3-1bd879f11128"
   },
   "outputs": [],
   "source": [
    "baseline_model.score(X = validation_sentences,\n",
    "                     y = validation_labels_label_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VoQ-ahRONYZe",
    "outputId": "4633d413-4ed6-45ed-9d99-7a8d7a4c2759"
   },
   "outputs": [],
   "source": [
    "baseline_preds = baseline_model.predict(validation_sentences)\n",
    "baseline_results = calculate_results(y_true = validation_labels_label_encoded,\n",
    "                                     y_pred = baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RpFTfoacO5mZ",
    "outputId": "27f2d257-4600-4123-beef-dd6d608a8419"
   },
   "outputs": [],
   "source": [
    "sentence_lengths = [len(sentence.split()) for sentence in train_sentences]\n",
    "average_sentence_length = np.mean(sentence_lengths)\n",
    "average_sentence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "id": "xpZNVva3Pdt-",
    "outputId": "a85d44c0-d22f-45f5-dfbd-a1da0887d6e3"
   },
   "outputs": [],
   "source": [
    "plt.hist(sentence_lengths, bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-4M3E5eWPxku",
    "outputId": "cb1da370-32fc-4a86-f8c8-94f3fee8629b"
   },
   "outputs": [],
   "source": [
    "output_sentence_length = int(np.percentile(sentence_lengths, 95))\n",
    "output_sentence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MvFQzvp6QXHb"
   },
   "outputs": [],
   "source": [
    "max_tokens = 68000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wl511YJeNvuk"
   },
   "outputs": [],
   "source": [
    "token_vectorizer = tf.keras.layers.TextVectorization(max_tokens = max_tokens,\n",
    "                                                                               output_sequence_length = output_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fjuXQxGdawly"
   },
   "outputs": [],
   "source": [
    "token_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k7qlLJKra9CU",
    "outputId": "563146e2-0eaa-4885-dcd3-ed9882323b49"
   },
   "outputs": [],
   "source": [
    "sample_sentence = random.choice(train_sentences)\n",
    "print(f'Text:\\n{sample_sentence}')\n",
    "print(f'\\nLength of sentence: {len(sample_sentence.split())}')\n",
    "print(f'\\nVectorized text: {token_vectorizer([sample_sentence])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S9TVP3nhb5Jb",
    "outputId": "94c94160-ef24-41e9-f297-25fb96921140"
   },
   "outputs": [],
   "source": [
    "token_vocab = token_vectorizer.get_vocabulary()\n",
    "print(f'Number of words in token_vocab: {len(token_vocab)}')\n",
    "print(f'Most common words in token_vocab: {(token_vocab[:10])}')\n",
    "print(f'Least common words in token_vocab: {(token_vocab[-10:])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHwZmB0bcXCR",
    "outputId": "801fc01a-a955-4bb6-9caf-922ea4ecab2f"
   },
   "outputs": [],
   "source": [
    "token_vectorizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8SDxSxLcaXw"
   },
   "outputs": [],
   "source": [
    "token_embedder = tf.keras.layers.Embedding(input_dim = len(token_vocab),\n",
    "                                          output_dim = 128,\n",
    "                                          mask_zero = True,\n",
    "                                          name = 'token_embedding_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LSRKcr8lgeVT",
    "outputId": "6c35711f-9ae3-4fd8-9e41-72fd6ea5a660"
   },
   "outputs": [],
   "source": [
    "print(f'Sentence:\\n {sample_sentence}\\n')\n",
    "vectorized_sample_sentence = token_vectorizer([sample_sentence])\n",
    "print(f'Vectorized sentence:\\n{vectorized_sample_sentence}\\n')\n",
    "embedded_sample_sentence = token_embedder(vectorized_sample_sentence)\n",
    "print(f'Embedded sentence:\\n{embedded_sample_sentence}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-wCa_INRhojW"
   },
   "outputs": [],
   "source": [
    "train_token_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot_encoded))\n",
    "validation_token_data = tf.data.Dataset.from_tensor_slices((validation_sentences, validation_labels_one_hot_encoded))\n",
    "test_token_data = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFWKf1YbjrSH"
   },
   "outputs": [],
   "source": [
    "train_token_data = train_token_data.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "validation_token_data = validation_token_data.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_token_data = test_token_data.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h8Rwn2WqkJWa"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape = (1,), dtype = tf.string)\n",
    "text_vectors = token_vectorizer(inputs)\n",
    "text_embeddings = token_embedder(text_vectors)\n",
    "x = tf.keras.layers.Conv1D(64, kernel_size = 5, padding = 'same', activation = 'relu')(text_embeddings)\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "outputs = tf.keras.layers.Dense(total_classes, activation = 'softmax')(x)\n",
    "model_1 = tf.keras.Model(inputs, outputs, name = 'conv1d_20k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nrGuXYZDltO1"
   },
   "outputs": [],
   "source": [
    "model_1.compile(loss = tf.keras.losses.categorical_crossentropy,\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate = 0.003),\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SLlmuechl4Q1",
    "outputId": "e11bac9c-fe23-446b-eadc-abf6ef7f9267"
   },
   "outputs": [],
   "source": [
    "model_1_history = model_1.fit(train_token_data,\n",
    "                              epochs = 5,\n",
    "                              steps_per_epoch = int(0.25 * len(train_token_data)),\n",
    "                              validation_data = validation_token_data,\n",
    "                              validation_steps = int(0.25 * len(validation_token_data)),\n",
    "                              callbacks=[create_tensorboard_callback(dir_name = LOGS_DIR, experiment_name = 'conv1d_20k')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "od9e3NFFnX7h",
    "outputId": "1a27c2ac-2b0c-43e8-b597-42b474eeb1d4"
   },
   "outputs": [],
   "source": [
    "model_1.evaluate(validation_token_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PVzkZs5Ao38_",
    "outputId": "7394f7c5-3be0-48b5-a007-e231154f6a76"
   },
   "outputs": [],
   "source": [
    "model_1_preds = tf.argmax(model_1.predict(validation_token_data), axis = 1)\n",
    "model_1_preds, validation_labels_one_hot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iYKdD4eOpMdq",
    "outputId": "2d08e0ce-8635-453c-8978-66906fcca1d4"
   },
   "outputs": [],
   "source": [
    "model_1_results = calculate_results(y_true = validation_labels_label_encoded,\n",
    "                                    y_pred = model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AFFTcmOopocE"
   },
   "outputs": [],
   "source": [
    "use_layer = tfhub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\", trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2oFN76eHuK6_",
    "outputId": "4637f17c-e9bb-4c2f-801b-d433ef1d8fc2"
   },
   "outputs": [],
   "source": [
    "print(f'Sentence:\\n {sample_sentence}\\n')\n",
    "use_sample_sentence = use_layer([sample_sentence])\n",
    "print(f'Embedded sentence:\\n{use_sample_sentence}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5HEytIuXuxXD",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=[], name=\"Input\", dtype=tf.string)\n",
    "text_use_embedding = tf.keras.layers.Lambda(lambda x: use_layer(x), output_shape=(512,))(inputs)\n",
    "x = tf.keras.layers.Dense(128, activation = 'relu')(text_use_embedding)\n",
    "outputs = tf.keras.layers.Dense(total_classes, activation = 'softmax')(x)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name = 'use_20k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fmTPb9RCwFPv"
   },
   "outputs": [],
   "source": [
    "model_2.compile(loss = tf.keras.losses.categorical_crossentropy,\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate = 0.003),\n",
    "                metrics = ['accuracy'], jit_compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1SLWVCYPwQi5",
    "outputId": "c1df0862-bf05-414c-b62b-0c21591a8705"
   },
   "outputs": [],
   "source": [
    "model_2_history = model_2.fit(train_token_data,\n",
    "                              epochs = 5,\n",
    "                              steps_per_epoch = int(0.25 * len(train_token_data)),\n",
    "                              validation_data = validation_token_data,\n",
    "                              validation_steps = int(0.25 * len(validation_token_data)),\n",
    "                              callbacks = [create_tensorboard_callback(dir_name = LOGS_DIR, experiment_name = 'use_20k')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wiom2pz2wtuF",
    "outputId": "9c595b57-017c-45cf-acfd-8a69c5dbf3cc"
   },
   "outputs": [],
   "source": [
    "model_2.evaluate(validation_token_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "exRM2h6OxJCb",
    "outputId": "bddc1b82-bdf8-4b99-fa1a-84e75de98d4b"
   },
   "outputs": [],
   "source": [
    "model_2_preds = tf.argmax(model_2.predict(validation_token_data), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QImL0QYcxQu_",
    "outputId": "169d5843-b6b1-4ebd-8c42-76318e560dd6"
   },
   "outputs": [],
   "source": [
    "model_2_results = calculate_results(y_true = validation_labels_label_encoded,\n",
    "                                    y_pred = model_2_preds)\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJxtF7zmznhF"
   },
   "outputs": [],
   "source": [
    "def split_chars(text):\n",
    "  return ' '.join(list(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DQxduId3zs_P"
   },
   "outputs": [],
   "source": [
    "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
    "validation_chars = [split_chars(sentence) for sentence in validation_sentences]\n",
    "test_chars = [split_chars(sentence) for sentence in test_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X-LGMmz50Ber",
    "outputId": "aa81b834-7832-4cad-dd3f-2fdb0f715bbd"
   },
   "outputs": [],
   "source": [
    "character_lengths = [len(sentence) for sentence in train_sentences]\n",
    "average_character_length = np.mean(character_lengths)\n",
    "average_character_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "DDA9PwPy0BUh",
    "outputId": "5673db9f-3ce1-4187-da75-9e006f2be2a8"
   },
   "outputs": [],
   "source": [
    "plt.hist(character_lengths, bins = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p7DcJvJv0BIr",
    "outputId": "72f9f190-53ec-4c7d-fc30-18b271a2d15b"
   },
   "outputs": [],
   "source": [
    "output_character_length = int(np.percentile(character_lengths, 95))\n",
    "output_character_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "FbRQLCkz1Ygw",
    "outputId": "06eaa363-4c41-48af-cca1-c083c198acab"
   },
   "outputs": [],
   "source": [
    "characters = string.ascii_lowercase + string.digits + string.punctuation\n",
    "characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r3pARFKf2Bkt",
    "outputId": "2351f535-37d5-4966-b8a1-b0b8296d7dbb"
   },
   "outputs": [],
   "source": [
    "max_chars = len(characters) +2\n",
    "max_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5k2_mQyS2K7S"
   },
   "outputs": [],
   "source": [
    "char_vectorizer = tf.keras.layers.TextVectorization(max_tokens = max_chars,\n",
    "                                                    output_sequence_length = output_character_length,\n",
    "                                                    name = 'character_vectorizer_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2B43QEpw2K2w"
   },
   "outputs": [],
   "source": [
    "char_vectorizer.adapt(train_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TtjVDCK-2Kk1",
    "outputId": "186bf605-a53b-448a-9465-0c57af0ca18c"
   },
   "outputs": [],
   "source": [
    "char_vocab = char_vectorizer.get_vocabulary()\n",
    "print(f'Number of words in char_vocab: {len(char_vocab)}')\n",
    "print(f'Most common words in char_vocab: {(char_vocab[:10])}')\n",
    "print(f'Least common words in char_vocab: {(char_vocab[-10:])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Swc7-4e33gW",
    "outputId": "ee3588c5-4841-4cd5-af61-fed42c6b19f0"
   },
   "outputs": [],
   "source": [
    "char_vectorizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2kU9_KMmxd3J"
   },
   "outputs": [],
   "source": [
    "char_embedder = tf.keras.layers.Embedding(input_dim = len(char_vocab),\n",
    "                                               output_dim = 25,\n",
    "                                               mask_zero = True,\n",
    "                                               name = 'character_embedder_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82LP81ZkZ-f-",
    "outputId": "d9510d15-856d-42e9-dd36-f3b26056172b"
   },
   "outputs": [],
   "source": [
    "sample_chars = split_chars(sample_sentence)\n",
    "print(f'Sentence:\\n {sample_chars}\\n')\n",
    "vectorized_sample_chars = char_vectorizer([sample_chars])\n",
    "print(f'Vectorized sentence:\\n{vectorized_sample_chars}\\n')\n",
    "embedded_sample_chars = char_embedder(vectorized_sample_chars)\n",
    "print(f'Embedded sentence:\\n{embedded_sample_chars}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NoMvdem6cAAa"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape = (1, ), dtype = tf.string)\n",
    "char_vectors = char_vectorizer(inputs)\n",
    "char_embeddings = char_embedder(char_vectors)\n",
    "x = tf.keras.layers.Conv1D(64, kernel_size = 5, padding = 'same', activation = 'relu')(char_embeddings)\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "outputs = tf.keras.layers.Dense(total_classes, activation = 'softmax')(x)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name = 'conv1d_char_20k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QhhlkFrhdLNx"
   },
   "outputs": [],
   "source": [
    "model_3.compile(loss = tf.keras.losses.categorical_crossentropy,\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate = 0.003),\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uyGVY-WEdURP"
   },
   "outputs": [],
   "source": [
    "train_char_data = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot_encoded))\n",
    "validation_char_data = tf.data.Dataset.from_tensor_slices((validation_chars, validation_labels_one_hot_encoded))\n",
    "test_char_data = tf.data.Dataset.from_tensor_slices((test_chars, test_labels_one_hot_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_oLw2gNceaBE"
   },
   "outputs": [],
   "source": [
    "train_char_data = train_char_data.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "validation_char_data = validation_char_data.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_char_data = test_char_data.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uPviVwT-euTW",
    "outputId": "edd10fa0-a217-4d1d-8c37-41ca51b829b6"
   },
   "outputs": [],
   "source": [
    "model_3_history = model_3.fit(train_char_data,\n",
    "                              epochs = 5,\n",
    "                              steps_per_epoch = int(0.25 * len(train_char_data)),\n",
    "                              validation_data = validation_char_data,\n",
    "                              validation_steps = int(0.25 * len(validation_char_data)),\n",
    "                              callbacks = [create_tensorboard_callback(dir_name = LOGS_DIR, experiment_name = 'conv1d_char_20k')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XM-9CwEffl83",
    "outputId": "7cd01f5f-40ea-4c2a-919d-c22afa5537ca"
   },
   "outputs": [],
   "source": [
    "model_3.evaluate(validation_char_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yHaO7h2rfViL",
    "outputId": "478056a8-c0e5-4911-bb9f-2b264095a331"
   },
   "outputs": [],
   "source": [
    "model_3_preds = tf.argmax(model_3.predict(validation_char_data), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c_CNFO64fwSB",
    "outputId": "ec5ecec0-d14d-4e26-8795-36d2a0cd9949"
   },
   "outputs": [],
   "source": [
    "model_3_results = calculate_results(y_true = validation_labels_label_encoded,\n",
    "                                    y_pred = model_3_preds)\n",
    "model_3_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0pgjfd38f3wY"
   },
   "outputs": [],
   "source": [
    "token_inputs = tf.keras.layers.Input(shape=(), dtype=tf.string, name='token_input')\n",
    "token_embeddings = tf.keras.layers.Lambda(lambda x: use_layer(x), output_shape=(512,))(token_inputs)\n",
    "token_outputs = tf.keras.layers.Dense(256, activation='relu', name='token_output')(token_embeddings)\n",
    "token_model = tf.keras.Model(token_inputs, token_outputs, name='token_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHkGJHoAXo2o"
   },
   "outputs": [],
   "source": [
    "# Define the char input model\n",
    "char_inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string, name='char_input')\n",
    "char_vectors = char_vectorizer(char_inputs)\n",
    "char_embeddings = char_embedder(char_vectors)\n",
    "char_outputs = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(24), name='char_output')(char_embeddings)\n",
    "char_model = tf.keras.Model(char_inputs, char_outputs, name='char_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5z6TYEx7YU7E"
   },
   "outputs": [],
   "source": [
    "token_char_inputs = tf.keras.layers.Concatenate(name='token_char_input')([token_model.output, char_model.output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QR6PULrpZbEm"
   },
   "outputs": [],
   "source": [
    "token_char_dropout_1 = tf.keras.layers.Dropout(0.5, name='token_char_dropout_1')(token_char_inputs)\n",
    "token_char_dense = tf.keras.layers.Dense(128, activation='relu', name='token_char_dense')(token_char_dropout_1)\n",
    "token_char_dropout_2 = tf.keras.layers.Dropout(0.5, name='token_char_dropout_2')(token_char_dense)\n",
    "token_char_outputs = tf.keras.layers.Dense(total_classes, activation='softmax', name='token_char_output')(token_char_dropout_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J61tICawaF34"
   },
   "outputs": [],
   "source": [
    "model_4 = tf.keras.Model(inputs=[token_model.input, char_model.input], outputs=token_char_outputs, name='token_char_20k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "id": "1hGII9czbc8W",
    "outputId": "3f5a905e-f5c3-4324-f7c8-97d1ba4b799b"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model_4, show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZktqVlTebc4U"
   },
   "outputs": [],
   "source": [
    "train_token_char_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_chars))\n",
    "train_token_char_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot_encoded)\n",
    "train_token_char_dataset = tf.data.Dataset.zip((train_token_char_data, train_token_char_labels))\n",
    "\n",
    "validation_token_char_data = tf.data.Dataset.from_tensor_slices((validation_sentences, validation_chars))\n",
    "validation_token_char_labels = tf.data.Dataset.from_tensor_slices(validation_labels_one_hot_encoded)\n",
    "validation_token_char_dataset = tf.data.Dataset.zip((validation_token_char_data, validation_token_char_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LdJ0Sshzbcah"
   },
   "outputs": [],
   "source": [
    "train_token_char_dataset = train_token_char_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "validation_token_char_dataset = validation_token_char_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZLqo0gqaw9V"
   },
   "outputs": [],
   "source": [
    "model_4.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.003),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QTeb3vkHbcVn",
    "outputId": "786278f3-dc05-4e84-d30d-ddf579b214ef"
   },
   "outputs": [],
   "source": [
    "model_4_history = model_4.fit(\n",
    "    train_token_char_dataset,\n",
    "    epochs=5,\n",
    "    steps_per_epoch=int(0.25 * len(train_token_char_dataset)),\n",
    "    validation_data=validation_token_char_dataset,\n",
    "    validation_steps=int(0.25 * len(validation_token_char_dataset)),\n",
    "    callbacks=[create_tensorboard_callback(dir_name=LOGS_DIR, experiment_name='token_char_20k')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UgGvVmI6bcIG",
    "outputId": "39607497-b09a-468c-8a63-74492bf0d192"
   },
   "outputs": [],
   "source": [
    "model_4.evaluate(validation_token_char_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VyzfGuZkbE6q",
    "outputId": "592d1e13-7321-4982-8baf-2f0a0224eb55"
   },
   "outputs": [],
   "source": [
    "model_4_preds = tf.argmax(model_4.predict(validation_token_char_dataset), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wvP8DRYtgcuu",
    "outputId": "68b0e8c2-186e-495f-a53e-c61e73a5bd92"
   },
   "outputs": [],
   "source": [
    "model_4_results = calculate_results(y_true = validation_labels_label_encoded,\n",
    "                                    y_pred = model_4_preds)\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "rmKJ7TGugnMK",
    "outputId": "8dfe0635-64b1-4024-92d3-ba181f9d4214"
   },
   "outputs": [],
   "source": [
    "train_df['line_number'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4KGt3HpflzWQ"
   },
   "outputs": [],
   "source": [
    "train_line_numbers_one_hot_encoded = tf.one_hot(train_df['line_number'].to_numpy(), depth = 15)\n",
    "validation_line_numbers_one_hot_encoded = tf.one_hot(validation_df['line_number'].to_numpy(), depth = 15)\n",
    "test_line_numbers_one_hot_encoded = tf.one_hot(test_df['line_number'].to_numpy(), depth = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "V9AlcTeMPhHG",
    "outputId": "854a3120-eb5b-4827-c692-78c3260387eb"
   },
   "outputs": [],
   "source": [
    "train_df['total_lines'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBK47knOPlsJ"
   },
   "outputs": [],
   "source": [
    "train_total_lines_one_hot_encoded = tf.one_hot(train_df['total_lines'].to_numpy(), depth = 20)\n",
    "validation_total_lines_one_hot_encoded = tf.one_hot(validation_df['total_lines'].to_numpy(), depth = 20)\n",
    "test_total_lines_one_hot_encoded = tf.one_hot(test_df['total_lines'].to_numpy(), depth = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jdGu4GWDP5xh"
   },
   "outputs": [],
   "source": [
    "line_number_inputs = tf.keras.layers.Input(shape = (15, ), dtype = tf.float32, name = 'line_number_input')\n",
    "line_number_outputs = tf.keras.layers.Dense(32, activation = 'relu', name = 'line_number_output')(line_number_inputs)\n",
    "line_number_model = tf.keras.Model(line_number_inputs, line_number_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hCqRex52TQHs"
   },
   "outputs": [],
   "source": [
    "total_lines_inputs = tf.keras.layers.Input(shape = (20, ), dtype = tf.float32, name = 'total_lines_input')\n",
    "total_lines_outputs = tf.keras.layers.Dense(32, activation = 'relu', name = 'total_line_output')(total_lines_inputs)\n",
    "total_lines_model = tf.keras.Model(total_lines_inputs, total_lines_outputs, name = 'total_lines_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NrdV4Q5sT-S9"
   },
   "outputs": [],
   "source": [
    "token_char_dense = tf.keras.layers.Dense(256, activation = 'relu', name = 'token_char_dense')(token_char_inputs)\n",
    "token_char_dropout = tf.keras.layers.Dropout(0.5, name = 'token_char_dropout')(token_char_dense)\n",
    "token_char_positional_inputs = tf.keras.layers.Concatenate(name = 'token_char_positional_inputs')([line_number_model.output,\n",
    "                                                                                                   total_lines_model.output,\n",
    "                                                                                                   token_char_dropout])\n",
    "token_char_positional_outputs = tf.keras.layers.Dense(total_classes, activation = 'softmax', name = 'token_char_positional_output')(token_char_positional_inputs)\n",
    "model_5 = tf.keras.Model([line_number_model.input,\n",
    "                          total_lines_model.input,\n",
    "                          token_model.input,\n",
    "                          char_model.input],\n",
    "                         token_char_positional_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "fOrxD_dbXVBt",
    "outputId": "4f4014db-20a7-45cd-dfff-b7d51ae13a78"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z7tcApgeWhGR"
   },
   "outputs": [],
   "source": [
    "model_5.compile(loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing = 0.2),\n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate = 0.003),\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "krRaQrSRXY5t"
   },
   "outputs": [],
   "source": [
    "train_token_char_positional_data = tf.data.Dataset.from_tensor_slices((train_line_numbers_one_hot_encoded, train_total_lines_one_hot_encoded, train_sentences, train_chars))\n",
    "train_token_char_positional_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot_encoded)\n",
    "train_token_char_positional_dataset = tf.data.Dataset.zip((train_token_char_positional_data, train_token_char_positional_labels))\n",
    "validation_token_char_positional_data = tf.data.Dataset.from_tensor_slices((validation_line_numbers_one_hot_encoded, validation_total_lines_one_hot_encoded, validation_sentences, validation_chars))\n",
    "validation_token_char_positional_labels = tf.data.Dataset.from_tensor_slices(validation_labels_one_hot_encoded)\n",
    "validation_token_char_positional_dataset = tf.data.Dataset.zip((validation_token_char_positional_data, validation_token_char_positional_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sUv8eWxTbsIC"
   },
   "outputs": [],
   "source": [
    "train_token_char_positional_dataset = train_token_char_positional_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "validation_token_char_positional_dataset = validation_token_char_positional_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GiBfHUJJW_34",
    "outputId": "a85905b4-145b-4528-c521-d04f7db9f68f"
   },
   "outputs": [],
   "source": [
    "model_5_history = model_5.fit(train_token_char_positional_dataset,\n",
    "                              epochs = 5,\n",
    "                              steps_per_epoch = int(0.25 * len(train_token_char_positional_dataset)),\n",
    "                              validation_data = validation_token_char_positional_dataset,\n",
    "                              validation_steps = int(0.25 * len(validation_token_char_positional_dataset)),\n",
    "                              callbacks = [create_tensorboard_callback(dir_name = LOGS_DIR, experiment_name = 'token_char_positional_20k')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LbXuK176dL13",
    "outputId": "09755d37-26cd-4ad3-ebfa-225319393a48"
   },
   "outputs": [],
   "source": [
    "model_5.evaluate(validation_token_char_positional_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nhyHUjzhdRft",
    "outputId": "120733c7-f18d-4a8c-9f6c-d626ce3260fd"
   },
   "outputs": [],
   "source": [
    "model_5_preds = tf.argmax(model_5.predict(validation_token_char_positional_dataset), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_vcKC4XZdd50",
    "outputId": "654e3085-e467-4f61-b0d2-c946b60ca92b"
   },
   "outputs": [],
   "source": [
    "model_5_results = calculate_results(y_true = validation_labels_label_encoded,\n",
    "                                    y_pred = model_5_preds)\n",
    "model_5_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VfimDk2pnpiM"
   },
   "outputs": [],
   "source": [
    "all_models_results = pd.DataFrame({\n",
    "    'naive_bayes_model': baseline_results,\n",
    "    'token_model': model_1_results,\n",
    "    'use_model': model_2_results,\n",
    "    'char_model': model_3_results,\n",
    "    'token_char_model': model_4_results,\n",
    "    'token_char_positional_model': model_5_results\n",
    "})\n",
    "\n",
    "all_models_results = all_models_results.transpose()\n",
    "all_models_results.reset_index(inplace = True)\n",
    "all_models_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KUbfkMiNpqnQ"
   },
   "outputs": [],
   "source": [
    "all_models_results.plot(kind = 'bar', figsize = (10,7)).legend(bbox_to_anchor = (1.0,1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uMd_h-WR889n"
   },
   "outputs": [],
   "source": [
    "test_token_char_positional_data = tf.data.Dataset.from_tensor_slices((test_line_numbers_one_hot_encoded, test_total_lines_one_hot_encoded, test_sentences, test_chars))\n",
    "test_token_char_positional_labels = tf.data.Dataset.from_tensor_slices(test_labels_one_hot_encoded)\n",
    "test_token_char_positional_dataset = tf.data.Dataset.zip((test_token_char_positional_data, test_token_char_positional_labels))\n",
    "test_token_char_positional_dataset = test_token_char_positional_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WlKVHItb9uxu"
   },
   "outputs": [],
   "source": [
    "model_5_test_preds = tf.argmax(model_5.predict(test_token_char_positional_dataset), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8LUzh8SJ99Zo"
   },
   "outputs": [],
   "source": [
    "model_5_test_results = calculate_results(y_true = test_labels_label_encoded,\n",
    "                                         y_pred = model_5_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KQMSmuqr99O8"
   },
   "outputs": [],
   "source": [
    "model_5_test_results"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (myvenv)",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
