{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e9bce85-c2f6-4f77-918a-8737ab403700",
   "metadata": {},
   "source": [
    "## Overview of the Style Transfer Notebook\n",
    "\n",
    "This Jupyter Notebook is designed to facilitate interactive style transfer for images and videos using pre-trained deep learning models. The notebook allows users to upload media, select specific models for style transfer, and view the results directly within the interface.\n",
    "\n",
    "### Key Features:\n",
    "- **Media Upload Widgets**: Users can upload images and videos to predefined directories using intuitive file upload widgets.\n",
    "- **Style Transfer Processing**: Implements style transformation functions that standardize media into a format suitable for neural network processing. This includes resizing, tensor conversion, and normalization.\n",
    "- **Dynamic Model Selection**: Users can choose from a list of pre-trained models stored in a designated directory, enabling different styles to be applied to the uploaded media.\n",
    "- **Real-time Processing Feedback**: The process of uploading files, performing style transfer, and saving outputs is logged in real-time, providing transparency and feedback on the operations being performed.\n",
    "- **Output Visualization**: After processing, the stylized images and videos are displayed directly in the notebook, allowing for immediate review and comparison.\n",
    "\n",
    "### Technologies Used:\n",
    "- **PyTorch**: Utilized for building and applying neural network models for style transfer.\n",
    "- **Torchvision**: Provides image transformations and utilities to facilitate working with image data.\n",
    "- **IPython Widgets**: Creates an interactive GUI within the Jupyter environment, enhancing user engagement and ease of use.\n",
    "- **skvideo.io**: Handles video file writing and processing, ensuring high-quality video output.\n",
    "\n",
    "This notebook is perfect for users who wish to experiment with different style transfers on their media files or developers looking for an easily adaptable template for building more complex media processing workflows.\n",
    "\n",
    "### Required Datasets\n",
    "\n",
    "**Pre-trained Style Transfer Models**:\n",
    "\n",
    "The pre-trained models can be downloaded from the following Google Drive folder. Please download all the files at once to ensure you have the complete set of necessary models for this project.\n",
    "\n",
    "### How to Download Models\n",
    "To access and download all the models in one go, please follow these simplified steps:\n",
    "\n",
    "1. Visit the [Google Drive folder with pre-trained models](https://drive.google.com/drive/folders/1aRD6zakhcDImN2Y54qAT6f4801iLcCLB?usp=sharing).\n",
    "2. Click on the \"Download all\" button to download the models as a single compressed (zip) file.\n",
    "3. Unzip the downloaded file into the `models` directory within your project folder.\n",
    "\n",
    "## Install Required Packages\n",
    "\n",
    "To enhance the functionality of the environment, you may need to install some libraries not pre-installed in the CoreAI environment but required for this notebook. Follow these steps to install the necessary libraries from the `requirements.txt` file:\n",
    "\n",
    "### Create and Activate the Virtual Environment:\n",
    "\n",
    "Open your terminal or command prompt within the Jupyter notebook. `File -> New -> Terminal` and type `bash` to get a shell compatible with the following commands.\n",
    "\n",
    "Navigate to the project directory where the notebook is to set up the environment.\n",
    "\n",
    "Execute the following commands to create and activate the virtual environment:\n",
    "\n",
    "```bash\n",
    "python3 -m venv --system-site-packages myvenv\n",
    "source myvenv/bin/activate\n",
    "pip3 install ipykernel\n",
    "python -m ipykernel install --user --name=myvenv --display-name=\"Python (myvenv)\"\n",
    "```\n",
    "\n",
    "### Install Required Libraries\n",
    "\n",
    "Before running the following command in this Jupyter notebook, make sure you are in the directory where the Jupyter Notebook and virtual environment is located. Load the newly created \"Python (myenv)\" kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e6184f-4136-48e9-81d0-859a3e70f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!. ./myvenv/bin/activate; pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c9626c-b2e2-4822-9e9f-28e1818f8b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from models import TransformerNet, VGG16\n",
    "from utils import *\n",
    "from models import TransformerNet\n",
    "import tqdm\n",
    "import warnings\n",
    "from torch.autograd import Variable\n",
    "import skvideo.io\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from pathlib import Path\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233769f4-24b0-4a2c-9772-6e1620046b87",
   "metadata": {},
   "source": [
    "#### Image Upload Functionality\n",
    "\n",
    "This section sets up an interactive file upload widget allowing users to upload images to a specific target directory ('input/images'). It checks if the directory exists and creates it if necessary. The upload process is logged in detail, including the start of the upload, file handling, and a confirmation once files are saved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb6c41-b421-4161-ac28-a9adb5b1a85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_directory = 'input/images'\n",
    " \n",
    "# Ensure the target directory exists, create it if it does not\n",
    "if not os.path.exists(target_directory):\n",
    "    os.makedirs(target_directory)  # This will create the directory and any necessary parent directories\n",
    "    print(f\"Directory {target_directory} created.\")\n",
    "else:\n",
    "    print(f\"Target directory: {target_directory}\")\n",
    " \n",
    "# Function to handle uploaded files\n",
    "def handle_upload(change):\n",
    "    print(\"Upload started...\")\n",
    "    # Print the structure of 'change' to understand its content\n",
    "    print(change)\n",
    "    \n",
    "    for file_upload in change['new']:\n",
    "        print(f\"Handling file: {file_upload}\")\n",
    "        filepath = os.path.join(target_directory, file_upload['name'])\n",
    "        print(f\"Saving to: {filepath}\")\n",
    "        with open(filepath, 'wb') as f:\n",
    "            f.write(file_upload['content'])\n",
    "        print(f'Saved {file_upload[\"name\"]} to {filepath}')\n",
    "    # List the files in the target directory after upload\n",
    "    print(f'Files in target directory ({target_directory}): {list(Path(target_directory).glob(\"*\"))}')\n",
    "    print(\"Upload completed.\")\n",
    " \n",
    "# Create an output widget to capture print statements\n",
    "output = widgets.Output()\n",
    " \n",
    "# Create an upload widget\n",
    "upload_widget = widgets.FileUpload()\n",
    " \n",
    "# Function to handle the change event using output widget\n",
    "def handle_upload_with_output(change):\n",
    "    with output:\n",
    "        handle_upload(change)\n",
    " \n",
    "# Attach the observer to the upload widget\n",
    "upload_widget.observe(handle_upload_with_output, names='value')\n",
    " \n",
    "# Display the upload widget and output widget\n",
    "display(upload_widget, output)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e99f878-abc7-4a89-a950-66a4ed731089",
   "metadata": {},
   "source": [
    "#### Style Transformation and Image Processing\n",
    "\n",
    "Defines a `style_transform` function that standardizes images to a consistent format suitable for style transfer, including resizing, tensor conversion. The `load_model` function loads a pre-trained model, setting it to evaluation mode for inference. \n",
    "\n",
    "The `stylize_image` function applies the style transformation model to an input image, performing the style transfer. This function is triggered by an interactive button which allows the user to select an image and a model for style transfer. The processed image is saved and displayed in the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088a63fa-345b-48ba-9411-f43fb66a79ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure output directory exists\n",
    "os.makedirs(\"images/outputs\", exist_ok=True)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define a function for image transformations\n",
    "def style_transform():\n",
    "    return transforms.Compose([\n",
    "        Resize(512),  # or another size that fits the model\n",
    "        ToTensor(),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "# Load and prepare the model\n",
    "def load_model(checkpoint_path):\n",
    "    transformer = TransformerNet().to(device)\n",
    "    transformer.load_state_dict(torch.load(checkpoint_path,map_location=device))\n",
    "    transformer.eval()\n",
    "    return transformer\n",
    "\n",
    "# Perform style transfer\n",
    "def stylize_image(image_path, model):\n",
    "    image_tensor = Variable(style_transform()(Image.open(image_path))).to(device)\n",
    "    image_tensor = image_tensor.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        stylized_image = denormalize(model(image_tensor)).cpu()\n",
    "    return stylized_image\n",
    "\n",
    "# Function to get files from a directory with specific extensions\n",
    "def get_files(directory, extensions):\n",
    "    all_files = []\n",
    "    for ext in extensions:\n",
    "        all_files.extend(Path(directory).rglob(f'*.{ext}'))\n",
    "    return [str(file) for file in all_files]\n",
    "\n",
    "# Automatically find image paths and model checkpoint paths\n",
    "image_paths = get_files('input/images', ['jpg', 'jpeg', 'png'])  # Include other image extensions if needed\n",
    "model_paths = get_files('models', ['pth'])  # Include other model extensions if used\n",
    "\n",
    "image_selector = widgets.Dropdown(options=image_paths, description='Image:')\n",
    "model_selector = widgets.Dropdown(options=model_paths, description='Model:')\n",
    "run_button = widgets.Button(description='Stylize Image')\n",
    "\n",
    "# Output widget to display results\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        print(\"Stylizing...\")\n",
    "        model = load_model(model_selector.value)\n",
    "        stylized_image = stylize_image(image_selector.value, model)\n",
    "        fn = image_selector.value.split(\"/\")[-1]\n",
    "        save_image(stylized_image, f\"images/outputs/stylized-{fn}\")\n",
    "        print(f\"Saved stylized-{fn} in images/outputs/\")\n",
    "        display(Image.open(f\"images/outputs/stylized-{fn}\"))\n",
    "\n",
    "# Link button to function\n",
    "run_button.on_click(on_button_clicked)\n",
    "\n",
    "# Display widgets\n",
    "display(image_selector, model_selector, run_button, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7fdb0e-809f-4d68-8c26-632c25facffb",
   "metadata": {},
   "source": [
    "#### Video Upload Functionality\n",
    "\n",
    "Similar to the image upload functionality, this section provides a file upload widget specifically for videos. It supports multiple video formats and allows multiple files to be uploaded simultaneously. The uploaded videos are saved in the 'input/videos' directory, which is created if it does not exist. The upload details are logged for user confirmation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb0ae0-b405-43db-afad-fe16f65c4ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_directory = 'input/videos'\n",
    "\n",
    "# Ensure the target directory exists\n",
    "if not os.path.exists(target_directory):\n",
    "    os.makedirs(target_directory)\n",
    "    print(f\"Directory {target_directory} created.\")\n",
    "else:\n",
    "    print(f\"Target directory: {target_directory}\")\n",
    "\n",
    "# Function to handle uploaded files\n",
    "def handle_upload(change):\n",
    "    print(\"Upload started...\")\n",
    "    # Print the structure of 'change' to understand its content\n",
    "    print(change)\n",
    "    \n",
    "    for file_upload in change['new']:\n",
    "        print(f\"Handling file: {file_upload['name']}\")\n",
    "        filepath = os.path.join(target_directory, file_upload['name'])\n",
    "        print(f\"Saving to: {filepath}\")\n",
    "        with open(filepath, 'wb') as f:\n",
    "            f.write(file_upload['content'])\n",
    "        print(f'Saved {file_upload[\"name\"]} to {filepath}')\n",
    "    # List the files in the target directory after upload\n",
    "    print(f'Files in target directory ({target_directory}): {list(Path(target_directory).glob(\"*\"))}')\n",
    "    print(\"Upload completed.\")\n",
    "\n",
    "# Create an output widget to capture print statements\n",
    "output = widgets.Output()\n",
    "\n",
    "# Create an upload widget\n",
    "upload_widget = widgets.FileUpload(accept='video/*', multiple=True)\n",
    "\n",
    "# Function to handle the change event using output widget\n",
    "def handle_upload_with_output(change):\n",
    "    with output:\n",
    "        handle_upload(change)\n",
    "\n",
    "# Attach the observer to the upload widget\n",
    "upload_widget.observe(handle_upload_with_output, names='value')\n",
    "\n",
    "# Display the upload widget and output widget\n",
    "display(upload_widget, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4805bbfa-511c-44c0-9532-95c4d6c02b25",
   "metadata": {},
   "source": [
    "#### Video Processing for Style Transfer\n",
    "\n",
    "This block sets up the functionality for processing video files for style transfer. It includes a function to retrieve video files and model checkpoints from specified directories. Users can select a video file and a model checkpoint from dropdown menus.\n",
    "\n",
    "The `process_video` function extracts frames from the selected video, applies the style transfer to each frame using the specified model, and recompiles the frames into a new stylized video. The result is saved to the 'videos/outputs' directory and the completion is logged.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8800d20-a87b-4644-be0a-2ff693495133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "os.makedirs(\"videos/outputs\", exist_ok=True)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Function to get video files\n",
    "def get_video_files(directory, extensions=['mp4']):\n",
    "    return [str(p) for p in Path(directory).rglob('*') if p.suffix[1:] in extensions]\n",
    "\n",
    "# Function to get model files\n",
    "def get_model_files(directory, extensions=['pth']):\n",
    "    return [str(p) for p in Path(directory).rglob('*') if p.suffix[1:] in extensions]\n",
    "\n",
    "video_directory = 'input/videos'  # Path to video directory\n",
    "model_directory = 'models'        # Path to model directory\n",
    "\n",
    "videos = get_video_files(video_directory)\n",
    "models = get_model_files(model_directory)\n",
    "\n",
    "video_selector = widgets.Dropdown(options=videos, description='Select Video:')\n",
    "model_selector = widgets.Dropdown(options=models, description='Select Model:')\n",
    "format_selector = widgets.Dropdown(options=['mp4'], description='Output Format:')\n",
    "process_button = widgets.Button(description='Process Video')\n",
    "output = widgets.Output()\n",
    "\n",
    "def process_video(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        video_path = video_selector.value\n",
    "        model_path = model_selector.value\n",
    "        output_format = format_selector.value\n",
    "        transform = style_transform()  # Make sure this function is defined correctly\n",
    "        model = TransformerNet().to(device)  # Make sure TransformerNet is defined correctly\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.eval()\n",
    "        \n",
    "        stylized_frames = []\n",
    "        for frame in tqdm.tqdm(extract_frames(video_path), desc=\"Processing frames\"):  # Ensure extract_frames is defined\n",
    "            image_tensor = Variable(transform(frame)).to(device).unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                stylized_image = model(image_tensor)\n",
    "            stylized_frames.append(deprocess(stylized_image))  # Ensure deprocess is defined\n",
    "        \n",
    "        video_name = Path(video_path).stem\n",
    "        output_path = f\"videos/outputs/stylized-{video_name}.{output_format}\"\n",
    "        writer = skvideo.io.FFmpegWriter(output_path, outputdict={\n",
    "            '-vcodec': 'libx264' if output_format == 'avi' else 'libx264',  # Adjust codec according to needs\n",
    "            '-pix_fmt': 'yuv420p'\n",
    "        })\n",
    "        for frame in tqdm.tqdm(stylized_frames, desc=\"Writing to video\"):\n",
    "            writer.writeFrame(frame)\n",
    "        writer.close()\n",
    "        \n",
    "        print(f\"Video processed and saved to {output_path}\")\n",
    "        shutil.copy(output_path, \"videos/lastest.mp4\")\n",
    "\n",
    "process_button.on_click(process_video)\n",
    "display(video_selector, model_selector, format_selector, process_button, output)\n",
    "vfile = \"videos/lastest.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdc6e8b-463e-4b79-b7a2-671290ad88d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(vfile, embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b8caf5-c28a-47a7-81c6-bbce020f9df3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myvenv)",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
