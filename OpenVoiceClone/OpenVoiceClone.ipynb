{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenVoice: Advanced Voice Cloning and Synthesis\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "OpenVoice is a cutting-edge project dedicated to the development of voice cloning and speech synthesis technologies. This repository hosts the tools and models necessary for implementing state-of-the-art voice cloning capabilities, enabling users to create lifelike synthetic voices from audio samples.\n",
    "\n",
    "## Voice Translation Widgets\n",
    "\n",
    "This application provides a user-friendly interface for voice translation. Below are the features available:\n",
    "\n",
    "### Features\n",
    "\n",
    "1. **Voice Upload**: Users can upload their voice recordings in MP3 format.\n",
    "   \n",
    "2. **Language Selection**: A dropdown menu allows users to select the language of the text to which the uploaded voice will be translated.\n",
    "   \n",
    "3. **Text Input Box**: Users can input or edit the text that will be translated into the selected language using the uploaded voice.\n",
    "\n",
    "### Usage\n",
    "\n",
    "- **Uploading Voice**: Click on the 'Upload' button and select an MP3 file from your device.\n",
    "- **Selecting Language**: Use the dropdown to choose the target language for translation.\n",
    "- **Entering Text**: Type into the text box the text you want to use for translation.\n",
    "\n",
    "This application is designed to be intuitive and easy to use, ensuring that users can quickly translate voices with minimal effort.\n",
    "\n",
    "## Setup and Installation\n",
    "\n",
    "## How To Use\n",
    "\n",
    "1. **Setup Environment**:\n",
    "   - Clone the repository or download the specific project files.\n",
    "   - Ensure Python 3.x is installed.\n",
    "\n",
    "2. **Install Required Packages**:\n",
    "\n",
    "   - To enhance the functionality of the CTPO environment, you may need to install some libraries not pre-installed but required for this notebook. Follow these steps to install the necessary libraries from the `requirements.txt` file:\n",
    "\n",
    "   **2.1 Create and Activate the Virtual Environment:**\n",
    "   \n",
    "   Open your terminal or command prompt within the jupyter notebook. `File -> New -> Terminal`\n",
    "   \n",
    "   Navigate to the project directory where you want to set up the environment.\n",
    "   \n",
    "   Execute the following commands to create and activate the virtual environment:\n",
    "   \n",
    "   ```\n",
    "   bash\n",
    "   python3 -m venv --system-site-packages myvenv #myvenv is name of virtual environment you can change it\n",
    "   source myvenv/bin/activate\n",
    "   pip3 install ipykernel\n",
    "   python -m ipykernel install --user --name=myvenv --display-name=\"Python (myvenv)\"\n",
    "   ```\n",
    "\n",
    " **2.2 Install Required Libraries**\n",
    "   \n",
    " Before running the following command in the Jupyter notebook, make sure you are in the directory where the Jupyter Notebook and virtual environment is located. Load the newly created \"Python (myvenv)\" kernel. This ensures the `./` path is always current. You can use the `cd` command to change to your project directory and `pwd` to verify your current directory.\n",
    "\n",
    "## Run the Notebook:\n",
    "- Open the `demo.ipynb` notebook in a Jupyter environment.\n",
    "-  Follow the instructions within the notebook, executing the code cells in sequence. Each cell includes comments explaining the purpose of the code, which will guide you through the demo process.\n",
    "- Make sure to read any embedded instructions or comments carefully to maximize your understanding and troubleshooting any issues that may arise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!. ./myvenv/bin/activate; pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation\n",
    "Download and prepare the model data:\n",
    "\n",
    "1. Create a directory for model checkpoints:\n",
    "2. Download the model checkpoint data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the directory 'checkpoints_v2' exists and download/unzip if it doesn't\n",
    "import os\n",
    "if not os.path.isdir(\"checkpoints_v2\"):\n",
    "    !wget https://myshell-public-repo-host.s3.amazonaws.com/openvoice/checkpoints_v2_0417.zip\n",
    "    !unzip checkpoints_v2_0417.zip\n",
    "    print(\"File downloaded and extracted.\")\n",
    "else:\n",
    "    print(\"Directory already exists, no need to download again.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a `HF_HOME` for HuggingFace downloads to cache locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('HF_HOME', exist_ok=True)\n",
    "os.environ['HF_HOME'] = 'HF_HOME'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download UniDic\n",
    "\"UniDic is a dictionary tool required for Japanese text processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!. ./myvenv/bin/activate; test -d /iti/myvenv/lib/python3.10/site-packages/unidic/dicdir || python -m unidic download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "Common Issues and Fixes\n",
    "CUDA Library Error: If you encounter an error related to libcublas.so.11, create a symbolic link to the newer version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -s /usr/local/cuda/lib64/libcublas.so.12 /usr/local/cuda/lib64/libcublas.so.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install portaudio: Portaudio is required for handling audio input and output in many applications. If you experience issues related to audio operations, ensure that `portaudio19-dev` is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! apt -q install -y portaudio19-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ensures that all dependencies for audio processing are properly configured.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from openvoice import se_extractor\n",
    "from openvoice.api import ToneColorConverter\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import  display, Audio\n",
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as wav\n",
    "from pydub import AudioSegment\n",
    "from io import BytesIO\n",
    "import base64\n",
    "from ipywidgets import FileUpload\n",
    "from base64 import b64decode\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "\n",
    "In this example, we will use the checkpoints from OpenVoiceV2. OpenVoiceV2 is trained with more aggressive augmentations and thus demonstrate better robustness in some cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_converter = 'checkpoints_v2/converter'\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "output_dir = 'outputs_v2'\n",
    "\n",
    "tone_color_converter = ToneColorConverter(f'{ckpt_converter}/config.json', device=device)\n",
    "tone_color_converter.load_ckpt(f'{ckpt_converter}/checkpoint.pth')\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Tone Color Embedding\n",
    "We only extract the tone color embedding for the target speaker. The source tone color embeddings can be directly loaded from `checkpoints_v2/ses` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_directory = 'resources/'\n",
    "reference_speaker = None\n",
    "\n",
    "# Ensure the target directory exists, create it if it does not\n",
    "if not os.path.exists(target_directory):\n",
    "    os.makedirs(target_directory)  # This will create the directory and any necessary parent directories\n",
    "    print(f\"Directory {target_directory} created.\")\n",
    "else:\n",
    "    print(f\"Target directory: {target_directory}\")\n",
    "\n",
    "# Function to handle uploaded files\n",
    "def handle_upload(change):\n",
    "    global reference_speaker\n",
    "    if change['new']:\n",
    "        print(\"Upload started...\")\n",
    "        # Print the structure of 'change' to understand its content\n",
    "        print(change)\n",
    "\n",
    "        for file_upload in change['new'].values():\n",
    "            print(f\"Handling file: {file_upload['name']}\")\n",
    "            filepath = os.path.join(target_directory, file_upload['name'])\n",
    "            print(f\"Saving to: {filepath}\")\n",
    "            reference_speaker = filepath\n",
    "            with open(filepath, 'wb') as f:\n",
    "                f.write(file_upload['content'])\n",
    "            print(f'Saved {file_upload[\"name\"]} to {filepath}')\n",
    "        # List the files in the target directory after upload\n",
    "        print(f'Files in target directory ({target_directory}): {list(Path(target_directory).glob(\"*\"))}')\n",
    "        print(\"Upload completed.\")\n",
    "        update_dropdown()  # Update dropdown after upload\n",
    "        dropdown.disabled = True  # Disable dropdown after upload\n",
    "        upload_widget.disabled = False  # Keep upload enabled if reset is needed\n",
    "\n",
    "print(\"Please select an audio file to use as reference speaker. If uploading your own, it is recommended to upload in MP3 format, a 30 second audio sample of spoken text.\")\n",
    "\n",
    "# Create an output widget to capture print statements\n",
    "output = widgets.Output()\n",
    "\n",
    "# Create an upload widget\n",
    "upload_widget = widgets.FileUpload(multiple=False)\n",
    "\n",
    "# Function to handle the change event using output widget\n",
    "def handle_upload_with_output(change):\n",
    "    with output:\n",
    "        handle_upload(change)\n",
    "\n",
    "# Attach the observer to the upload widget\n",
    "upload_widget.observe(handle_upload_with_output, names='value')\n",
    "\n",
    "# Create a Dropdown widget for selecting existing files\n",
    "def update_dropdown():\n",
    "    files = [file.name for file in Path(target_directory).glob('*.mp3')]\n",
    "    dropdown.options = files\n",
    "\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=[],\n",
    "    description='Select File:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "def dropdown_change(change):\n",
    "    if change['new']:\n",
    "        global reference_speaker\n",
    "        reference_speaker = os.path.join(target_directory, change['new'])\n",
    "        print(f\"Selected file: {reference_speaker}\")\n",
    "        upload_widget.disabled = True  # Disable upload after selection\n",
    "        dropdown.disabled = False  # Keep dropdown enabled if reset is needed\n",
    "\n",
    "dropdown.observe(dropdown_change, names='value')\n",
    "\n",
    "# Create a button to reset the selections\n",
    "reset_button = widgets.Button(description=\"Reset Selections\")\n",
    "\n",
    "def on_reset_clicked(b):\n",
    "    dropdown.disabled = False\n",
    "    upload_widget.disabled = False\n",
    "    update_dropdown()  # Update the dropdown list\n",
    "    print(\"Selections reset. You can upload a file or select from the dropdown.\")\n",
    "\n",
    "reset_button.on_click(on_reset_clicked)\n",
    "\n",
    "# Display the widgets and output widget\n",
    "display(upload_widget, dropdown, output, reset_button)\n",
    "update_dropdown()  # Initial update for the dropdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_se, audio_name = se_extractor.get_se(reference_speaker, tone_color_converter, vad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use MeloTTS as Base Speakers\n",
    "\n",
    "MeloTTS is a high-quality multi-lingual text-to-speech library by @MyShell.ai, supporting languages including English (American, British, Indian, Australian, Default), Spanish, French, Chinese, Japanese, Korean. In the following example, we will use the models in MeloTTS as the base speakers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from melo.api import TTS\n",
    "def run_tts(language, text):\n",
    "    src_path = f'{output_dir}/tmp.wav'\n",
    "    speed = 1.0  # Adjustable speed\n",
    "\n",
    "    # Initialize the TTS model for the selected language\n",
    "    model = TTS(language=language, device=device)\n",
    "    speaker_ids = model.hps.data.spk2id\n",
    "\n",
    "    for speaker_key in speaker_ids.keys():\n",
    "        speaker_id = speaker_ids[speaker_key]\n",
    "        speaker_key = speaker_key.lower().replace('_', '-')\n",
    "        \n",
    "        source_se = torch.load(f'checkpoints_v2/base_speakers/ses/{speaker_key}.pth', map_location=device)\n",
    "        model.tts_to_file(text, speaker_id, src_path, speed=speed)\n",
    "        save_path = f'{output_dir}/output_v2_{speaker_key}.wav'\n",
    "\n",
    "        # Run the tone color converter\n",
    "        encode_message = \"@MyShell\"\n",
    "        tone_color_converter.convert(\n",
    "            audio_src_path=src_path, \n",
    "            src_se=source_se, \n",
    "            tgt_se=target_se, \n",
    "            output_path=save_path,\n",
    "            message=encode_message)\n",
    "\n",
    "        # Play the generated audio file\n",
    "        display(Audio(save_path, autoplay=True))\n",
    "        print(f\"Generated audio saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text-To-Speech Interface Overview\n",
    "\n",
    "This interactive section allows users to convert text into speech using a simple interface built with Jupyter widgets.\n",
    "\n",
    "### Features\n",
    "\n",
    "- **Language Selection**: Users can choose from multiple languages including English, Spanish, French, Chinese, Japanese, and Korean.\n",
    "- **Text Input**: Provides a textarea for entering or modifying text for speech conversion.\n",
    "- **Convert to Speech**: A button that initiates the conversion of text into speech based on the selected language.\n",
    "\n",
    "### Usage\n",
    "\n",
    "Upon selecting a language from the dropdown, the text area updates with a preloaded text specific to that language, which can be edited. Clicking the \"Convert to Speech\" button processes the entered text using the chosen language’s TTS capabilities.\n",
    "\n",
    "This tool is designed for demonstrations and educational use, offering a straightforward way to interact with TTS technology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predefined texts for demonstration; you might want to start with empty strings in practice.\n",
    "texts = {\n",
    "    'EN_NEWEST': \"Did you ever hear a folk tale about a giant turtle?\",  # The newest English base speaker model\n",
    "    'EN': \"Did you ever hear a folk tale about a giant turtle?\",\n",
    "    'ES': \"El resplandor del sol acaricia las olas, pintando el cielo con una paleta deslumbrante.\",\n",
    "    'FR': \"La lueur dorée du soleil caresse les vagues, peignant le ciel d'une palette éblouissante.\",\n",
    "    'ZH': \"在这次vacation中，我们计划去Paris欣赏埃菲尔铁塔和卢浮宫的美景。\",\n",
    "    'JP': \"彼は毎朝ジョギングをして体を健康に保っています。\",\n",
    "    'KR': \"안녕하세요! 오늘은 날씨가 정말 좋네요.\",\n",
    "}\n",
    "\n",
    "# Create widgets\n",
    "language_dropdown = widgets.Dropdown(\n",
    "    options=[('English - Newest', 'EN_NEWEST'), ('English', 'EN'), ('Spanish', 'ES'), \n",
    "             ('French', 'FR'), ('Chinese', 'ZH'), ('Japanese', 'JP'), ('Korean', 'KR')],\n",
    "    value='EN_NEWEST',\n",
    "    description='Language:',\n",
    ")\n",
    "\n",
    "text_input = widgets.Textarea(\n",
    "    value=texts[language_dropdown.value],\n",
    "    placeholder='Type something',\n",
    "    description='Text:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def update_text_input(*args):\n",
    "    text_input.value = texts[language_dropdown.value]\n",
    "\n",
    "language_dropdown.observe(update_text_input, 'value')\n",
    "\n",
    "button = widgets.Button(description=\"Convert to Speech\")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        language = language_dropdown.value\n",
    "        text = text_input.value\n",
    "        print(f\"Processing TTS for {language}: '{text}'\")\n",
    "        run_tts(language, text)  # Call the TTS function with selected language and text\n",
    "\n",
    "button.on_click(on_button_clicked)\n",
    "\n",
    "# Display widgets\n",
    "display(language_dropdown, text_input, button, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (openvoicevenv)",
   "language": "python",
   "name": "openvoicevenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
